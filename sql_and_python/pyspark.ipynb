{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+--------------------+-------------+------------------+\n",
      "|First Name|Last Name|   Sex|               Email|Date of birth|         Job Title|\n",
      "+----------+---------+------+--------------------+-------------+------------------+\n",
      "|    Shelby|  Terrell|  Male|elijah57@example.net|   26/10/1945|   Games developer|\n",
      "|   Phillip|  Summers|Female|bethany14@example...|   24/03/1910|    Phytotherapist|\n",
      "|  Kristine|   Travis|  Male|bthompson@example...|   02/07/1992|         Homeopath|\n",
      "|   Yesenia| Martinez|  Male|kaitlinkaiser@exa...|   03/08/2017| Market researcher|\n",
      "|      Lori|     Todd|  Male|buchananmanuel@ex...|   01/12/1938|Veterinary surgeon|\n",
      "|      ABCd|     NULL|Female|                  **|         NULL|              NULL|\n",
      "+----------+---------+------+--------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 - Read the CSV file\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName('DataTransformations').getOrCreate()\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read.csv(\"C:/Users/karab/Desktop/Self-Learning/people_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows\n",
    "df.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+--------------------+-------------+------------------+\n",
      "|First Name|Last Name| Sex|               Email|Date of birth|         Job Title|\n",
      "+----------+---------+----+--------------------+-------------+------------------+\n",
      "|    Shelby|  Terrell|Male|elijah57@example.net|   26/10/1945|   Games developer|\n",
      "|  Kristine|   Travis|Male|bthompson@example...|   02/07/1992|         Homeopath|\n",
      "|   Yesenia| Martinez|Male|kaitlinkaiser@exa...|   03/08/2017| Market researcher|\n",
      "|      Lori|     Todd|Male|buchananmanuel@ex...|   01/12/1938|Veterinary surgeon|\n",
      "+----------+---------+----+--------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Filter Data Based on Condition (e.g., Sex = Male)\n",
    "filtered_df = df.filter(df['Sex'] == 'Male')\n",
    "filtered_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+--------------------+-------------+------------------+-------------+------------------+\n",
      "|First Name|Last Name|   Sex|               Email|Date of birth|         Job Title|Date_of_birth|               Age|\n",
      "+----------+---------+------+--------------------+-------------+------------------+-------------+------------------+\n",
      "|    Shelby|  Terrell|  Male|elijah57@example.net|   26/10/1945|   Games developer|   1945-10-26|              79.2|\n",
      "|   Phillip|  Summers|Female|bethany14@example...|   24/03/1910|    Phytotherapist|   1910-03-24|114.81643835616438|\n",
      "|  Kristine|   Travis|  Male|bthompson@example...|   02/07/1992|         Homeopath|   1992-07-02|32.484931506849314|\n",
      "|   Yesenia| Martinez|  Male|kaitlinkaiser@exa...|   03/08/2017| Market researcher|   2017-08-03| 7.380821917808219|\n",
      "|      Lori|     Todd|  Male|buchananmanuel@ex...|   01/12/1938|Veterinary surgeon|   1938-12-01| 86.10684931506849|\n",
      "|      ABCd|     NULL|Female|                  **|         NULL|              NULL|         NULL|              NULL|\n",
      "+----------+---------+------+--------------------+-------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Add a New Column (e.g., Age)\n",
    "\n",
    "from pyspark.sql.functions import to_date, current_date, datediff\n",
    "\n",
    "# Convert 'Date of birth' to date type (if not already)\n",
    "df_with_date = df.withColumn('Date_of_birth', to_date(df['Date of birth'], 'dd/MM/yyyy'))\n",
    "\n",
    "# Calculate age by subtracting 'Date of birth' from the current date\n",
    "df_with_age = df_with_date.withColumn('Age', datediff(current_date(), df_with_date['Date_of_birth']) / 365)\n",
    "df_with_age.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "|First Name|Last Name|   Sex|Date of birth|         Job Title|Date_of_birth|               Age|\n",
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "|    Shelby|  Terrell|  Male|   26/10/1945|   Games developer|   1945-10-26|              79.2|\n",
      "|   Phillip|  Summers|Female|   24/03/1910|    Phytotherapist|   1910-03-24|114.81643835616438|\n",
      "|  Kristine|   Travis|  Male|   02/07/1992|         Homeopath|   1992-07-02|32.484931506849314|\n",
      "|   Yesenia| Martinez|  Male|   03/08/2017| Market researcher|   2017-08-03| 7.380821917808219|\n",
      "|      Lori|     Todd|  Male|   01/12/1938|Veterinary surgeon|   1938-12-01| 86.10684931506849|\n",
      "|      ABCd|     NULL|Female|         NULL|              NULL|         NULL|              NULL|\n",
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Drop Column\n",
    "\n",
    "df_dropped = df_with_age.drop('Email')\n",
    "df_dropped.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "|First_Name|Last_Name|   Sex|Date of birth|         Job Title|Date_of_birth|               Age|\n",
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "|    Shelby|  Terrell|  Male|   26/10/1945|   Games developer|   1945-10-26|              79.2|\n",
      "|   Phillip|  Summers|Female|   24/03/1910|    Phytotherapist|   1910-03-24|114.81643835616438|\n",
      "|  Kristine|   Travis|  Male|   02/07/1992|         Homeopath|   1992-07-02|32.484931506849314|\n",
      "|   Yesenia| Martinez|  Male|   03/08/2017| Market researcher|   2017-08-03| 7.380821917808219|\n",
      "|      Lori|     Todd|  Male|   01/12/1938|Veterinary surgeon|   1938-12-01| 86.10684931506849|\n",
      "|      ABCd|     NULL|Female|         NULL|              NULL|         NULL|              NULL|\n",
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5. Change Column Name\n",
    "df_renamed = df_dropped.withColumnRenamed('First Name', 'First_Name') \\\n",
    "                       .withColumnRenamed('Last Name', 'Last_Name')\n",
    "df_renamed.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+\n",
      "|         Job Title|Number_of_People|\n",
      "+------------------+----------------+\n",
      "|   Games developer|               1|\n",
      "|              NULL|               1|\n",
      "|         Homeopath|               1|\n",
      "|Veterinary surgeon|               1|\n",
      "| Market researcher|               1|\n",
      "|    Phytotherapist|               1|\n",
      "+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Group By and Aggregate (e.g., Count by Job Title)\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "df_grouped = df_renamed.groupBy('Job Title').agg(count('First_Name').alias('Number_of_People'))\n",
    "df_grouped.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+--------------------+-------------+------------------+-------------+------------------+\n",
      "|First Name|Last Name|   Sex|               Email|Date of birth|         Job Title|Date_of_birth|               Age|\n",
      "+----------+---------+------+--------------------+-------------+------------------+-------------+------------------+\n",
      "|   Phillip|  Summers|Female|bethany14@example...|   24/03/1910|    Phytotherapist|   1910-03-24|114.81643835616438|\n",
      "|      Lori|     Todd|  Male|buchananmanuel@ex...|   01/12/1938|Veterinary surgeon|   1938-12-01| 86.10684931506849|\n",
      "|    Shelby|  Terrell|  Male|elijah57@example.net|   26/10/1945|   Games developer|   1945-10-26|              79.2|\n",
      "|  Kristine|   Travis|  Male|bthompson@example...|   02/07/1992|         Homeopath|   1992-07-02|32.484931506849314|\n",
      "|   Yesenia| Martinez|  Male|kaitlinkaiser@exa...|   03/08/2017| Market researcher|   2017-08-03| 7.380821917808219|\n",
      "|      ABCd|     NULL|Female|                  **|         NULL|              NULL|         NULL|              NULL|\n",
      "+----------+---------+------+--------------------+-------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Sort Data by a Column (e.g., Age)\n",
    "\n",
    "df_sorted = df_with_age.orderBy(df_with_age['Age'], ascending=False)\n",
    "df_sorted.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "|First_Name|Last_Name|   Sex|Date of birth|         Job Title|Date_of_birth|               Age|\n",
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "|    Shelby|  Terrell|  Male|   26/10/1945|   Games developer|   1945-10-26|              79.2|\n",
      "|   Phillip|  Summers|Female|   24/03/1910|    Phytotherapist|   1910-03-24|114.81643835616438|\n",
      "|  Kristine|   Travis|  Male|   02/07/1992|         Homeopath|   1992-07-02|32.484931506849314|\n",
      "|   Yesenia| Martinez|  Male|   03/08/2017| Market researcher|   2017-08-03| 7.380821917808219|\n",
      "|      Lori|     Todd|  Male|   01/12/1938|Veterinary surgeon|   1938-12-01| 86.10684931506849|\n",
      "|      ABCd|     NULL|Female|         NULL|           Unknown|         NULL|              NULL|\n",
      "+----------+---------+------+-------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Replace Values in a Column (e.g., Replace NULL with 'Unknown')\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_replaced = df_renamed.withColumn('Job Title', \n",
    "                                   when(df_renamed['Job Title'].isNull(), 'Unknown')\n",
    "                                   .otherwise(df_renamed['Job Title']))\n",
    "df_replaced.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+------+--------------------+-------------+------------------+-------------+\n",
      "|First Name|Last Name|   Sex|               Email|Date of birth|         Job Title|Date_of_birth|\n",
      "+----------+---------+------+--------------------+-------------+------------------+-------------+\n",
      "|    Shelby|  Terrell|  Male|elijah57@example.net|   26/10/1945|   Games developer|   1945-10-26|\n",
      "|   Phillip|  Summers|Female|bethany14@example...|   24/03/1910|    Phytotherapist|   1910-03-24|\n",
      "|  Kristine|   Travis|  Male|bthompson@example...|   02/07/1992|         Homeopath|   1992-07-02|\n",
      "|   Yesenia| Martinez|  Male|kaitlinkaiser@exa...|   03/08/2017| Market researcher|   2017-08-03|\n",
      "|      Lori|     Todd|  Male|buchananmanuel@ex...|   01/12/1938|Veterinary surgeon|   1938-12-01|\n",
      "|      ABCd|     NULL|Female|                  **|         NULL|              NULL|         NULL|\n",
      "+----------+---------+------+--------------------+-------------+------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Change Data Type of a Column (e.g., String to Date for 'Date of Birth')\n",
    "\n",
    "df_with_date = df.withColumn('Date_of_birth', to_date(df['Date of birth'], 'dd/MM/yyyy'))\n",
    "df_with_date.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|              [79.2]|[0.6684857448870302]|\n",
      "|[114.81643835616438]|               [1.0]|\n",
      "|[32.484931506849314]|[0.23366654766154...|\n",
      "| [7.380821917808219]|               [0.0]|\n",
      "| [86.10684931506849]|[0.7327740092823991]|\n",
      "|               [NaN]|               [NaN]|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Standardize the Column (e.g., Normalize the Age)\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# Create a DataFrame for MinMaxScaler input\n",
    "df_for_scaling = df_with_age.select('Age').rdd.map(lambda row: (Vectors.dense([row['Age']]),)).toDF([\"features\"])\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Fit and transform data\n",
    "scaler_model = scaler.fit(df_for_scaling)\n",
    "scaled_df = scaler_model.transform(df_for_scaling)\n",
    "\n",
    "# Show normalized data\n",
    "scaled_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
